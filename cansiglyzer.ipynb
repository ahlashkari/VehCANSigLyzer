{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CANSigLyzer\n",
    "\n",
    "In this notebook, we extract and select features from CAN-MIRGU, which is a dataset of raw CAN frames collected from a single vehicle by [Rajapaksha et al. (2024)](https://www.ndss-symposium.org/ndss-paper/auto-draft-482/).\n",
    "\n",
    "**Data**: The dataset used is [CAN-MIRGU](https://github.com/sampathrajapaksha/CAN-MIRGU), which contains both benign and attack data from an unknown 2016 vehicle model. It is a fully electric vehicle with full autonomous driving capabilities. \n",
    "\n",
    "**DBC**: We use a DBC obtained from [opendbc](https://github.com/commaai/opendbc), which is an open-source repository of reverse-engineered DBC files contributed by car hacking enthusiasts. \n",
    "\n",
    "The paper does not reveal the exact model of the test vehicle, except for the aforementioned details. Apart from this, the AIDs and some associated signals (from the dataset and attack metadata) are known and a [video](https://www.youtube.com/watch?v=CufiACr2Zs8) of the attacks being conducted while the car is being driven is available. However, the car is most likely a Kia since the interior of the test car is a visual match for Kia car interiors from 2016 and we find all the AIDs used in the attacks in the [hyundai_kia_generic.dbc](https://github.com/commaai/opendbc/blob/master/opendbc/dbc/hyundai_kia_generic.dbc) file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import pickle\n",
    "import os\n",
    "import cantools\n",
    "from importlib import reload\n",
    "from tqdm import tqdm\n",
    "\n",
    "import helper_functions\n",
    "from helper_functions import *\n",
    "import gc\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import shapiro\n",
    "from sklearn.feature_selection import mutual_info_classif, f_classif, VarianceThreshold\n",
    "from matplotlib_venn import venn3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame for summary stats\n",
    "summary_stats = pd.DataFrame(columns=['Log', 'Type', 'Real/Simulated', 'No. of benign frames', 'No. of attack frames', 'Total no. of frames', 'Total duration', 'Start timestamp', 'End timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in benign files\n",
    "dfs_benign = {}                             # List of all preprocessed benign logs\n",
    "\n",
    "print(\"Reading benign files..\")\n",
    "for i in tqdm(range(1, 7)):\n",
    "    fpath = \"CAN-MIRGU/Benign/Day_\" + str(i) + \"/\"\n",
    "    for lname in os.listdir(fpath):\n",
    "        # print(lname)\n",
    "        df = pd.read_csv(fpath + lname)     # Read in log\n",
    "        df = preprocessDataset(df)          # Preprocess into tabular form\n",
    "        df['attack_class'] = '0'              # Add attack class column      \n",
    "        dfs_benign[lname] = df              # Append to list of benign logs\n",
    "\n",
    "        duration = df.timestamp[len(df) - 1] - df.timestamp[0]\n",
    "        summary_stats = pd.concat([summary_stats if not summary_stats.empty else None, pd.DataFrame([[lname, 'Benign', 'Real', len(df), 0, len(df), duration, df.timestamp[0], df.timestamp[len(df) - 1]]], columns=summary_stats.columns)], ignore_index=True)\n",
    "\n",
    "# Save list of benign log names\n",
    "benign_lnames = list(dfs_benign.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in real attack files\n",
    "dfs_attack = {}\n",
    "\n",
    "fpath = \"CAN-MIRGU/Attack/Real_attacks/\"\n",
    "attack_lnames = list(os.listdir(fpath))\n",
    "\n",
    "print(\"Reading real attack files..\")\n",
    "for i in tqdm(range(len(attack_lnames))):\n",
    "    lname = attack_lnames[i]\n",
    "    # print(lname)\n",
    "    df = pd.read_csv(fpath + lname)     # Read in log\n",
    "    df = preprocessDataset(df)          # Preprocess into tabular form\n",
    "    df['attack_class'] = '0'              # Add attack class column\n",
    "    dfs_attack[lname] = df              # Append to list of attack logs  \n",
    "\n",
    "    benign_frames = len(df[df.attack == '0'])\n",
    "    duration = df.timestamp[len(df) - 1] - df.timestamp[0]\n",
    "    summary_stats = pd.concat([summary_stats, pd.DataFrame([[lname, 'Attack', 'Real', benign_frames, len(df)-benign_frames, len(df), duration, df.timestamp[0], df.timestamp[len(df) - 1]]], columns=summary_stats.columns)], ignore_index=True)\n",
    "\n",
    "# Save list of attack log names\n",
    "attack_lnames = list(dfs_attack.keys())\n",
    "\n",
    "with open('output/attack_lnames', 'wb') as fp:\n",
    "    pickle.dump(attack_lnames, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in simulated attack files\n",
    "\n",
    "dfs_simulated_attack = {}\n",
    "\n",
    "# Suspension attacks\n",
    "fpath = \"CAN-MIRGU/Attack/Suspension_attacks/\"\n",
    "simulated_attack_lnames = list(os.listdir(fpath))\n",
    "\n",
    "print(\"Reading suspension attack files..\")\n",
    "for i in tqdm(range(len(simulated_attack_lnames))):\n",
    "    lname = simulated_attack_lnames[i]\n",
    "    df = pd.read_csv(fpath + lname)     # Read in log\n",
    "    df = preprocessDataset(df)          # Preprocess into tabular form\n",
    "    df['attack_class'] = '0'             # Add attack class column\n",
    "    dfs_simulated_attack[lname] = df    # Append to list of attack logs  \n",
    "\n",
    "    benign_frames = len(df[df.attack == '0'])\n",
    "    duration = df.timestamp[len(df) - 1] - df.timestamp[0]\n",
    "    summary_stats = pd.concat([summary_stats, pd.DataFrame([[lname, 'Attack', 'Simulated', benign_frames, len(df)-benign_frames, len(df), duration, df.timestamp[0], df.timestamp[len(df) - 1]]], columns=summary_stats.columns)], ignore_index=True)\n",
    "\n",
    "# Masquerade attacks\n",
    "fpath = \"CAN-MIRGU/Attack/Masquerade_attacks/\"   \n",
    "simulated_attack_lnames = list(os.listdir(fpath))\n",
    "\n",
    "print(\"Reading masquerade attack files..\")\n",
    "for i in tqdm(range(len(simulated_attack_lnames))):\n",
    "    lname = simulated_attack_lnames[i]\n",
    "    df = pd.read_csv(fpath + lname)     # Read in log\n",
    "    df = preprocessDataset(df)          # Preprocess into tabular form\n",
    "    df['attack_class'] = '0'              # Add attack class column\n",
    "    dfs_simulated_attack[lname] = df    # Append to list of attack logs  \n",
    "\n",
    "    benign_frames = len(df[df.attack == '0'])\n",
    "    duration = df.timestamp[len(df) - 1] - df.timestamp[0]\n",
    "    summary_stats = pd.concat([summary_stats, pd.DataFrame([[lname, 'Attack', 'Simulated', benign_frames, len(df)-benign_frames, len(df), duration, df.timestamp[0], df.timestamp[len(df) - 1]]], columns=summary_stats.columns)], ignore_index=True)\n",
    "\n",
    "simulated_attack_lnames = list(dfs_simulated_attack.keys())   # Save list of attack log names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary stats\n",
    "print(\"Summary stats for all logs\")\n",
    "print(\"--------------------------\")\n",
    "display(summary_stats)      # Per log\n",
    "summary_stats.to_csv(\"output/summary_stats.csv\", index=False, index_label=False)\n",
    "print(\"No. of benign logs         =\", len(dfs_benign))\n",
    "print(\"No. of attack logs         =\", len(dfs_attack))\n",
    "print()\n",
    "print(\"Total no. of benign frames =\", sum(summary_stats['No. of benign frames']))\n",
    "print(\"Total no. of attack frames =\", sum(summary_stats['No. of attack frames']))\n",
    "print(\"Total no. of frames        =\", sum(summary_stats['Total no. of frames']))\n",
    "print()\n",
    "\n",
    "# Real attacks only\n",
    "print(\"Summary for real attack logs\")\n",
    "print(\"----------------------------\")\n",
    "print(\"No. of real attack logs    =\", len(summary_stats[summary_stats['Real/Simulated'] == 'Real']))\n",
    "print()\n",
    "print(\"Total no. of benign frames =\", (summary_stats[summary_stats['Real/Simulated'] == 'Real'])['No. of benign frames'].sum())\n",
    "print(\"Total no. of attack frames =\", (summary_stats[summary_stats['Real/Simulated'] == 'Real'])['No. of attack frames'].sum())\n",
    "print(\"Total no. of frames        =\", (summary_stats[summary_stats['Real/Simulated'] == 'Real'])['Total no. of frames'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check sample\n",
    "print('Benign_day1_file1.log')\n",
    "print('---------------------')\n",
    "display(dfs_benign['Benign_day1_file1.log'].head())\n",
    "\n",
    "print('Fuzzing_random_IDs.log')\n",
    "print('----------------------')\n",
    "display(dfs_attack['Fuzzing_random_IDs.log'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labelling\n",
    "\n",
    "We convert the binary labels in the real attack datasets to multiclass labels indicating the attack type:\n",
    "\n",
    "| Label | Attack type             | \n",
    "|-------|-------------------------|\n",
    "| 0     | Benign                  | \n",
    "| 1     | Denial of service (DoS) |\n",
    "| 2     | Fuzzing                 | \n",
    "| 3     | Spoofing (Targeted ID)  | \n",
    "| 4     | Replay                  |\n",
    "\n",
    "We convert the binary labels in the simulated attack datasets in the following way: \n",
    "| Label | Attack type             | \n",
    "|-------|-------------------------|\n",
    "| 0     | Benign                  | \n",
    "| 5     | Suspension              |\n",
    "| 6     | Masquerade              |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real attack types, only logs with single attack type\n",
    "attack_label_dict = {\n",
    "    \"1\" : [\"DoS_attack.log\"],\n",
    "    \"2\" : [\"Fuzzing_random_IDs.log\", \"Fuzzing_valid_IDs.log\"],\n",
    "    \"3\" : [\"Steering_angle_attack.log\", \"Break_and_fog_light_attack.log\", \"Break_warning_attack.log\", \"Drive_mode_changing_attack.log\", \"FCA_warning_attack.log\", \"Power_steering_attack.log\", \"Max_speedometer_attack.log\", \"Min_speedometer_attack_1.log\",  \"Min_speedometer_attack_2.log\", \"Min_speedometer_attack_3.log\", \"Wiper_warning_attack.log\", \"EMS_attack.log\", \"Parking_break_attack.log\", \"Gear_shifter_attack_1.log\", \"Gear_shifter_attack_2.log\", \"Door_open_warning_attack.log\"],\n",
    "    \"4\" : [\"EMS_replay_attack.log\", \"EMS_replay_long_attack.log\", \"Steering_angle_replay.log\"]\n",
    "}\n",
    "\n",
    "for key in attack_label_dict.keys():\n",
    "    for lname in attack_label_dict[key]:\n",
    "        # dfs_attack[lname].loc[dfs_attack[lname]['attack'] == \"1\", 'attack'] = key\n",
    "        dfs_attack[lname].loc[dfs_attack[lname]['attack'] == \"1\", 'attack_class'] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 4 logs with multiple windows of mixed attack type\n",
    "# Although JSON metadata is available, we choose to label these messages manually\n",
    "\n",
    "# Labelling mixed attack logs\n",
    "\n",
    "# 1. Fuzzing + DoS\n",
    "lname = \"Fuzzing_valid_IDs_DoS.log\"\n",
    "dfs_attack[lname].loc[(dfs_attack[lname].timestamp >= 1698322348.170193) & (dfs_attack[lname].timestamp <= 1698322359.125561) & (dfs_attack[lname].attack == '1'), 'attack_class'] = \"1\"\n",
    "dfs_attack[lname].loc[(dfs_attack[lname].timestamp >= 1698322411.631589) & (dfs_attack[lname].timestamp <= 1698322412.975203) & (dfs_attack[lname].attack == '1'), 'attack_class'] = \"2\"\n",
    "\n",
    "# # 2. Reverse speedometer spoofing + Fuzzing\n",
    "lname = \"Reverse_speedometer_fuzzing_attack.log\"\n",
    "dfs_attack[lname].loc[(dfs_attack[lname].timestamp >= 1698324056.378570) & (dfs_attack[lname].timestamp <= 1698324077.578847) & (dfs_attack[lname].attack == '1'), 'attack_class'] = \"3\"\n",
    "dfs_attack[lname].loc[(dfs_attack[lname].timestamp >= 1698324112.495487) & (dfs_attack[lname].timestamp <= 1698324114.937510) & (dfs_attack[lname].attack == '1'), 'attack_class'] = \"2\"\n",
    "\n",
    "# # 3. Multiple attacks - 1\n",
    "lname = \"Multiple_attacks_1.log\"\n",
    "dfs_attack[lname].loc[(dfs_attack[lname].timestamp >= 1698324526.792025) & (dfs_attack[lname].timestamp <= 1698324665.423766) & (dfs_attack[lname].attack == '1'), 'attack_class'] = \"3\"\n",
    "dfs_attack[lname].loc[(dfs_attack[lname].timestamp >= 1698324741.986758) & (dfs_attack[lname].timestamp <= 1698324888.386439) & (dfs_attack[lname].attack == '1'), 'attack_class'] = \"3\"\n",
    "dfs_attack[lname].loc[(dfs_attack[lname].timestamp >= 1698324989.299539) & (dfs_attack[lname].timestamp <= 1698325020.489142) & (dfs_attack[lname].attack == '1'), 'attack_class'] = \"3\"\n",
    "\n",
    "# # 4. Multiple attacks - 2\n",
    "lname = \"Multiple_attacks_2.log\"\n",
    "dfs_attack[lname].loc[(dfs_attack[lname].timestamp >= 1698325268.088982) & (dfs_attack[lname].timestamp <= 1698325445.142059) & (dfs_attack[lname].attack == '1'), 'attack_class'] = \"3\"\n",
    "dfs_attack[lname].loc[(dfs_attack[lname].timestamp >= 1698325547.014587) & (dfs_attack[lname].timestamp <= 1698325677.014188) & (dfs_attack[lname].attack == '1'), 'attack_class'] = \"3\"\n",
    "dfs_attack[lname].loc[(dfs_attack[lname].timestamp >= 1698325749.869002) & (dfs_attack[lname].timestamp <= 1698325855.270239) & (dfs_attack[lname].attack == '1'), 'attack_class'] = \"3\"\n",
    "dfs_attack[lname].loc[(dfs_attack[lname].timestamp >= 1698325910.117414) & (dfs_attack[lname].timestamp <= 1698326015.332354) & (dfs_attack[lname].attack == '1'), 'attack_class'] = \"3\"\n",
    "dfs_attack[lname].loc[(dfs_attack[lname].timestamp >= 1698326059.786127) & (dfs_attack[lname].timestamp <= 1698326100.519047) & (dfs_attack[lname].attack == '1'), 'attack_class'] = \"2\"\n",
    "dfs_attack[lname].loc[(dfs_attack[lname].timestamp >= 1698326212.341763) & (dfs_attack[lname].timestamp <= 1698326238.622524) & (dfs_attack[lname].attack == '1'), 'attack_class'] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labelling simulated attack types\n",
    "\n",
    "for lname in simulated_attack_lnames:\n",
    "    label = '5' if 'suspension' in lname else '6'\n",
    "    dfs_simulated_attack[lname].loc[dfs_simulated_attack[lname]['attack'] == \"1\", 'attack_class'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as CSV\n",
    "\n",
    "print(\"Writing benign logs to disk..\")\n",
    "for i in tqdm(range(len(benign_lnames))):\n",
    "    lname = benign_lnames[i]\n",
    "    dfs_benign[lname].to_csv(\"output/CSV_Raw_Binary/\" + lname.rstrip(\".log\") + \".csv\", index=False, index_label=False)\n",
    "\n",
    "print(\"Writing real attack logs to disk..\")\n",
    "for i in tqdm(range(len(attack_lnames))):\n",
    "    lname = attack_lnames[i]\n",
    "    dfs_attack[lname].to_csv(\"output/CSV_Raw_Binary/\" + lname.rstrip(\".log\") + \".csv\", index=False, index_label=False)\n",
    "\n",
    "print(\"Writing simulated attack logs to disk..\")\n",
    "for i in tqdm(range(len(simulated_attack_lnames))):\n",
    "    lname = simulated_attack_lnames[i]\n",
    "    dfs_simulated_attack[lname].to_csv(\"output/CSV_Raw_Binary/\" + lname.rstrip(\".log\") + \".csv\", index=False, index_label=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Raw dataset\n",
    "These datasets have columns `timestamp`, `arbitration_id`, `data_0`, `data_1`, ... , `data_7`, `attack`, `attack_class`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in ['CAN-MIRGU/Attack', 'CAN-MIRGU/Benign']:\n",
    "    sub_folders = os.listdir(folder)\n",
    "    sub_folders = [x for x in sub_folders if os.path.isdir(folder + \"/\" + x)]\n",
    "    for sub_folder in sub_folders:                      # Day_1, Day_2, ...\n",
    "        sub_folder_path = folder + \"/\" + sub_folder     # CAN-MIRGU/Benign/Day_1, CAN-MIRGU/Benign/Day_2, ...\n",
    "        sub_folder_files = os.listdir(sub_folder_path)  # Benign_day1_file1.log, Benign_day1_file2.log, ...\n",
    "        for file in sub_folder_files:\n",
    "            if folder == 'CAN-MIRGU/Benign':            # Get the right DataFrame\n",
    "                df = dfs_benign[file]\n",
    "            else:\n",
    "                df = dfs_attack[file] if file in attack_lnames else dfs_simulated_attack[file]\n",
    "\n",
    "            data_cols = ['data_{}'.format(i) for i in range(8)] # Convert data_field to data columns\n",
    "            df[data_cols] = df['data_field'].apply(lambda x: [x[i:i+2] if i < len(x) else np.nan for i in range(0, 16, 2)]).apply(pd.Series)\n",
    "            df = df[['timestamp', 'arbitration_id'] + data_cols + ['attack', 'attack_class']]\n",
    "            \n",
    "            # Write to correct location in raw_dataset\n",
    "            if folder == 'CAN-MIRGU/Benign':\n",
    "                write_folder_path = 'raw_dataset/Benign/' + sub_folder + '/' + file.rstrip('.log') + '.csv'\n",
    "            else:\n",
    "                write_folder_path = 'raw_dataset/Attack/' + sub_folder + '/' + file.rstrip('.log') + '.csv'\n",
    "            df.to_csv(write_folder_path, index=False, index_label=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time intervals\n",
    "\n",
    "Absolute timestamps do not provide useful information for modelling on their own. However, time interval, i.e., the duration between a message and a previous message, can provide an indication of an attack because during an injection/fabrication attack, there are more messages on the CAN bus resulting in smaller time intervals between subsequent messages.\n",
    "\n",
    "We create two new features for each row/frame: \n",
    "* `time_interval`, which is the difference between the timestamp of a message and that of the message before it\n",
    "* `aid_time_interval`, which is the difference between the timestamp of a message and that of the message before it *with the same AID*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get time intervals\n",
    "for i in tqdm(range(len(benign_lnames))):\n",
    "    lname = benign_lnames[i]\n",
    "    dfs_benign[lname] = getTimeIntervals(dfs_benign[lname])\n",
    "\n",
    "for i in tqdm(range(len(attack_lnames))):\n",
    "    lname = attack_lnames[i]\n",
    "    dfs_attack[lname] = getTimeIntervals(dfs_attack[lname])\n",
    "\n",
    "for i in tqdm(range(len(simulated_attack_lnames))):\n",
    "    lname = simulated_attack_lnames[i]\n",
    "    dfs_simulated_attack[lname] = getTimeIntervals(dfs_simulated_attack[lname])\n",
    "\n",
    "# Check sample\n",
    "print('Benign_day2_file2.log')\n",
    "print('---------------------')\n",
    "display(dfs_benign['Benign_day2_file2.log'].head())\n",
    "\n",
    "print('Fuzzing_random_IDs.log')\n",
    "print('----------------------')\n",
    "display(dfs_attack['Fuzzing_random_IDs.log'].head())\n",
    "\n",
    "print('ID_07F_suspension_attack.log')\n",
    "print('----------------------')\n",
    "display(dfs_simulated_attack['ID_07F_suspension_attack.log'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"No. of unique AIDS:\", len(set(dfs_benign['Benign_day2_file2.log'].arbitration_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as CSV\n",
    "\n",
    "print(\"Writing benign logs to disk..\")\n",
    "for i in tqdm(range(len(benign_lnames))):\n",
    "    lname = benign_lnames[i]\n",
    "    dfs_benign[lname].to_csv(\"output/CSV_RawWithTimeIntervals_Multiclass/\" + lname.rstrip(\".log\") + \".csv\", index=False, index_label=False)\n",
    "\n",
    "print(\"Writing real attack logs to disk..\")\n",
    "for i in tqdm(range(len(attack_lnames))):\n",
    "    lname = attack_lnames[i]\n",
    "    dfs_attack[lname].to_csv(\"output/CSV_RawWithTimeIntervals_Multiclass/\" + lname.rstrip(\".log\") + \".csv\", index=False, index_label=False)\n",
    "\n",
    "print(\"Writing simulated attack logs to disk..\")\n",
    "for i in tqdm(range(len(simulated_attack_lnames))):\n",
    "    lname = simulated_attack_lnames[i]\n",
    "    dfs_simulated_attack[lname].to_csv(\"output/CSV_RawWithTimeIntervals_Multiclass/\" + lname.rstrip(\".log\") + \".csv\", index=False, index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average time intervals (aid_time_interval) for a single log\n",
    "\n",
    "reload(helper_functions)\n",
    "from helper_functions import *\n",
    "\n",
    "timeIntervalSummary_Benign_day3 = getTimeIntervalSummary(dfs_benign['Benign_day3_file1.log'])\n",
    "timeIntervalSummary_Benign_day3.to_csv(\"output/timeIntervalSummary_Benign_day3.csv\", index=False, index_label=False)\n",
    "\n",
    "# Visualize message counts\n",
    "fig = timeIntervalSummary_Benign_day3.set_index('arbitration_id').message_count.plot(kind='bar', figsize=(20, 7))\n",
    "fig.set(title=\"No. of messages of each AID in Benign_day3_file.log\", xlabel=\"AID\", ylabel=\"Count\")\n",
    "plt.show()\n",
    "\n",
    "# Visualize distribution of AIDs by mean time interval\n",
    "fig = timeIntervalSummary_Benign_day3.avg_time_interval.hist()\n",
    "fig.set(title=\"Distribution of AIDs by mean time interval in Benign_day3_file1.log\", xlabel=\"Average time interval (seconds)\", ylabel=\"No. of AIDs\")\n",
    "plt.show()\n",
    "\n",
    "# Visualize distribution of maximum percent error from mean time interval \n",
    "fig = timeIntervalSummary_Benign_day3.max_percent_error_mean.hist()\n",
    "fig.set(title=\"Distribution of maximum percent error from mean time interval in Benign_day3_file1.log\", xlabel=\"Maximum percent error\", ylabel=\"No. of AIDs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deserializing signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No. of AIDs defined in DBC = 145\n"
     ]
    }
   ],
   "source": [
    "# Load the DBC file\n",
    "with open(\"hyundai_kia_generic.dbc\") as fin:\n",
    "    db_kia = cantools.database.load(fin)\n",
    "print(db_kia.version)\n",
    "print(\"No. of AIDs defined in DBC =\", len(db_kia.messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_benign\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_interval</th>\n",
       "      <th>aid_time_interval</th>\n",
       "      <th>arbitration_id</th>\n",
       "      <th>07F.C_DRLLampLhOpenSts</th>\n",
       "      <th>07F.C_DRLLampRhOpenSts</th>\n",
       "      <th>07F.C_FrontEXTTailLhOpenSts</th>\n",
       "      <th>07F.C_FrontEXTTailRhOpenSts</th>\n",
       "      <th>07F.C_FrontFOGLhOpenSts</th>\n",
       "      <th>07F.C_FrontFOGRhOpenSts</th>\n",
       "      <th>07F.C_FrontTSIGLhOpenSts</th>\n",
       "      <th>...</th>\n",
       "      <th>593.PRESSURE_RR</th>\n",
       "      <th>593.STATUS_TPMS</th>\n",
       "      <th>593.TPMS_W_LAMP</th>\n",
       "      <th>593.TREAD_W_LAMP</th>\n",
       "      <th>593.UNIT</th>\n",
       "      <th>596.CR_Ldc_ActVol_LS_V</th>\n",
       "      <th>5B0.CF_Clu_Odometer</th>\n",
       "      <th>5FF.CF_Vcu_EpbRequest</th>\n",
       "      <th>attack</th>\n",
       "      <th>attack_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.536743e-07</td>\n",
       "      <td>0.009973</td>\n",
       "      <td>140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.087904e-03</td>\n",
       "      <td>0.009998</td>\n",
       "      <td>153</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.192093e-06</td>\n",
       "      <td>0.009999</td>\n",
       "      <td>160</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.009998</td>\n",
       "      <td>164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.536743e-07</td>\n",
       "      <td>0.009999</td>\n",
       "      <td>220</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 550 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_interval  aid_time_interval arbitration_id  07F.C_DRLLampLhOpenSts  \\\n",
       "0   9.536743e-07           0.009973            140                     NaN   \n",
       "1   1.087904e-03           0.009998            153                     NaN   \n",
       "2   1.192093e-06           0.009999            160                     NaN   \n",
       "3   0.000000e+00           0.009998            164                     NaN   \n",
       "4   9.536743e-07           0.009999            220                     NaN   \n",
       "\n",
       "   07F.C_DRLLampRhOpenSts  07F.C_FrontEXTTailLhOpenSts  \\\n",
       "0                     NaN                          NaN   \n",
       "1                     NaN                          NaN   \n",
       "2                     NaN                          NaN   \n",
       "3                     NaN                          NaN   \n",
       "4                     NaN                          NaN   \n",
       "\n",
       "   07F.C_FrontEXTTailRhOpenSts  07F.C_FrontFOGLhOpenSts  \\\n",
       "0                          NaN                      NaN   \n",
       "1                          NaN                      NaN   \n",
       "2                          NaN                      NaN   \n",
       "3                          NaN                      NaN   \n",
       "4                          NaN                      NaN   \n",
       "\n",
       "   07F.C_FrontFOGRhOpenSts  07F.C_FrontTSIGLhOpenSts  ...  593.PRESSURE_RR  \\\n",
       "0                      NaN                       NaN  ...              NaN   \n",
       "1                      NaN                       NaN  ...              NaN   \n",
       "2                      NaN                       NaN  ...              NaN   \n",
       "3                      NaN                       NaN  ...              NaN   \n",
       "4                      NaN                       NaN  ...              NaN   \n",
       "\n",
       "   593.STATUS_TPMS  593.TPMS_W_LAMP  593.TREAD_W_LAMP  593.UNIT  \\\n",
       "0              NaN              NaN               NaN       NaN   \n",
       "1              NaN              NaN               NaN       NaN   \n",
       "2              NaN              NaN               NaN       NaN   \n",
       "3              NaN              NaN               NaN       NaN   \n",
       "4              NaN              NaN               NaN       NaN   \n",
       "\n",
       "   596.CR_Ldc_ActVol_LS_V  5B0.CF_Clu_Odometer  5FF.CF_Vcu_EpbRequest  attack  \\\n",
       "0                     NaN                  NaN                    NaN       0   \n",
       "1                     NaN                  NaN                    NaN       0   \n",
       "2                     NaN                  NaN                    NaN       0   \n",
       "3                     NaN                  NaN                    NaN       0   \n",
       "4                     NaN                  NaN                    NaN       0   \n",
       "\n",
       "   attack_class  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "\n",
       "[5 rows x 550 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_attack\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_interval</th>\n",
       "      <th>aid_time_interval</th>\n",
       "      <th>arbitration_id</th>\n",
       "      <th>07F.C_DRLLampLhOpenSts</th>\n",
       "      <th>07F.C_DRLLampRhOpenSts</th>\n",
       "      <th>07F.C_FrontEXTTailLhOpenSts</th>\n",
       "      <th>07F.C_FrontEXTTailRhOpenSts</th>\n",
       "      <th>07F.C_FrontFOGLhOpenSts</th>\n",
       "      <th>07F.C_FrontFOGRhOpenSts</th>\n",
       "      <th>07F.C_FrontTSIGLhOpenSts</th>\n",
       "      <th>...</th>\n",
       "      <th>593.PRESSURE_RR</th>\n",
       "      <th>593.STATUS_TPMS</th>\n",
       "      <th>593.TPMS_W_LAMP</th>\n",
       "      <th>593.TREAD_W_LAMP</th>\n",
       "      <th>593.UNIT</th>\n",
       "      <th>596.CR_Ldc_ActVol_LS_V</th>\n",
       "      <th>5B0.CF_Clu_Odometer</th>\n",
       "      <th>5FF.CF_Vcu_EpbRequest</th>\n",
       "      <th>attack</th>\n",
       "      <th>attack_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.010463</td>\n",
       "      <td>2B0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.010467</td>\n",
       "      <td>251</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.009107</td>\n",
       "      <td>340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001777</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>153</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001051</td>\n",
       "      <td>0.009893</td>\n",
       "      <td>160</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 550 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_interval  aid_time_interval arbitration_id  07F.C_DRLLampLhOpenSts  \\\n",
       "0       0.001000           0.010463            2B0                     NaN   \n",
       "1       0.000002           0.010467            251                     NaN   \n",
       "2       0.001018           0.009107            340                     NaN   \n",
       "3       0.001777           0.009800            153                     NaN   \n",
       "4       0.001051           0.009893            160                     NaN   \n",
       "\n",
       "   07F.C_DRLLampRhOpenSts  07F.C_FrontEXTTailLhOpenSts  \\\n",
       "0                     NaN                          NaN   \n",
       "1                     NaN                          NaN   \n",
       "2                     NaN                          NaN   \n",
       "3                     NaN                          NaN   \n",
       "4                     NaN                          NaN   \n",
       "\n",
       "   07F.C_FrontEXTTailRhOpenSts  07F.C_FrontFOGLhOpenSts  \\\n",
       "0                          NaN                      NaN   \n",
       "1                          NaN                      NaN   \n",
       "2                          NaN                      NaN   \n",
       "3                          NaN                      NaN   \n",
       "4                          NaN                      NaN   \n",
       "\n",
       "   07F.C_FrontFOGRhOpenSts  07F.C_FrontTSIGLhOpenSts  ...  593.PRESSURE_RR  \\\n",
       "0                      NaN                       NaN  ...              NaN   \n",
       "1                      NaN                       NaN  ...              NaN   \n",
       "2                      NaN                       NaN  ...              NaN   \n",
       "3                      NaN                       NaN  ...              NaN   \n",
       "4                      NaN                       NaN  ...              NaN   \n",
       "\n",
       "   593.STATUS_TPMS  593.TPMS_W_LAMP  593.TREAD_W_LAMP  593.UNIT  \\\n",
       "0              NaN              NaN               NaN       NaN   \n",
       "1              NaN              NaN               NaN       NaN   \n",
       "2              NaN              NaN               NaN       NaN   \n",
       "3              NaN              NaN               NaN       NaN   \n",
       "4              NaN              NaN               NaN       NaN   \n",
       "\n",
       "   596.CR_Ldc_ActVol_LS_V  5B0.CF_Clu_Odometer  5FF.CF_Vcu_EpbRequest  attack  \\\n",
       "0                     NaN                  NaN                    NaN       0   \n",
       "1                     NaN                  NaN                    NaN       0   \n",
       "2                     NaN                  NaN                    NaN       0   \n",
       "3                     NaN                  NaN                    NaN       0   \n",
       "4                     NaN                  NaN                    NaN       0   \n",
       "\n",
       "   attack_class  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "\n",
       "[5 rows x 550 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test signal deserialization\n",
    "print(\"df_benign\")\n",
    "df_benign = pd.read_csv(\"output/CSV_RawWithTimeIntervals_Multiclass/Benign_day1_file1.csv\", nrows=250000)\n",
    "df_benign = deserializeCANDataFrame(df_benign, db_kia, attack=False)\n",
    "display(df_benign.head())\n",
    "\n",
    "print(\"df_attack\")\n",
    "df_attack = pd.read_csv(\"output/CSV_RawWithTimeIntervals_Multiclass/Fuzzing_random_IDs.csv\", nrows=250000)\n",
    "df_attack = deserializeCANDataFrame(df_attack, db_kia, attack=True, signals=[col for col in df_benign.columns if col not in ['time_interval', 'aid_time_interval', 'arbitration_id', 'attack', 'attack_class']])\n",
    "display(df_attack.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in both samples are the same: True\n"
     ]
    }
   ],
   "source": [
    "# Check if the columns in the samples are the same\n",
    "print(\"Columns in both samples are the same:\", sorted(df_benign.columns) == sorted(df_attack.columns))\n",
    "\n",
    "# Save list of all columns with valid signals\n",
    "colnames = df_benign.columns\n",
    "with open('output/colnames', 'wb') as fp:\n",
    "    pickle.dump(list(colnames), fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete large variables not needed any more\n",
    "del dfs_benign, dfs_attack, df_benign, df_attack\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**All attack datasets have the new headers that include `attack` and `attack_class`.**\n",
    "\n",
    "**Benign datasets have not been converted to this new schema yet, except `Benign_day3_file1.csv`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# CHANGE\n",
    "\n",
    "# for folder in ['CAN-MIRGU/Attack/', 'CAN-MIRGU/Benign']:\n",
    "#     sub_folders = os.listdir(folder)                    # Day_1, Day_2, ...\n",
    "#     sub_folders = [x for x in sub_folders if os.path.isdir(folder + \"/\" + x)]\n",
    "#     for sub_folder in sub_folders:                      \n",
    "#         sub_folder_path = folder + \"/\" + sub_folder     # CAN-MIRGU/Benign/Day_1, CAN-MIRGU/Benign/Day_2, ...\n",
    "#         sub_folder_files = os.listdir(sub_folder_path)  # Benign_day1_file1.log, Benign_day1_file2.log, ...\n",
    "#         for file in sub_folder_files:\n",
    "#             fp = \"CSV_Signals_Multiclass/\" + file.rstrip(\".log\") + \".csv\"\n",
    "#             df = pd.read_csv(fp)\n",
    "\n",
    "#             df['attack_class'] = df['attack']\n",
    "#             df['attack'] = df['attack_class'].apply(lambda x: 0 if x == 0 else 1)\n",
    "            \n",
    "#             # Write to correct location in raw_dataset\n",
    "#             if folder == 'CAN-MIRGU/Benign':\n",
    "#                 write_folder_path = 'signal_dataset/Benign/' + sub_folder + '/' + file.rstrip('.log') + '.csv'\n",
    "#             else:\n",
    "#                 write_folder_path = 'signal_dataset/Attack/' + sub_folder + '/' + file.rstrip('.log') + '.csv'\n",
    "#             df.to_csv(write_folder_path, index=False, index_label=False)\n",
    "\n",
    "#             # Delete original file \n",
    "#             os.remove(fp)\n",
    "\n",
    "for folder in ['CAN-MIRGU/Benign']:\n",
    "    sub_folders = ['Day_1', 'Day_2', 'Day_4', 'Day_5', 'Day_6']\n",
    "    for sub_folder in sub_folders:                      \n",
    "        sub_folder_path = folder + \"/\" + sub_folder     # CAN-MIRGU/Benign/Day_1, CAN-MIRGU/Benign/Day_2, ...\n",
    "        sub_folder_files = os.listdir(sub_folder_path)  # Benign_day1_file1.log, Benign_day1_file2.log, ...\n",
    "        for file in sub_folder_files:\n",
    "            fp = \"CSV_Signals_Multiclass/\" + file.rstrip(\".log\") + \".csv\"\n",
    "            df = pd.read_csv(fp)\n",
    "\n",
    "            df['attack_class'] = df['attack']\n",
    "            df['attack'] = (df['attack_class'] != 0).astype(int)\n",
    "\n",
    "            # Write to correct location in raw_dataset\n",
    "            if folder == 'CAN-MIRGU/Benign':\n",
    "                write_folder_path = 'signal_dataset/Benign/' + sub_folder + '/' + file.rstrip('.log') + '.csv'\n",
    "            else:\n",
    "                write_folder_path = 'signal_dataset/Attack/' + sub_folder + '/' + file.rstrip('.log') + '.csv'\n",
    "            df.to_csv(write_folder_path, index=False, index_label=False)\n",
    "\n",
    "            # Delete original file \n",
    "            os.remove(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deserialize signals in benign data\n",
    "import re\n",
    "for i in tqdm(range(len(benign_lnames))):\n",
    "    lname = benign_lnames[i]\n",
    "    fp = \"output/CSV_RawWithTimeIntervals_Multiclass/\" + lname.rstrip(\".log\") + \".csv\"\n",
    "    df = pd.read_csv(fp)\n",
    "    df = deserializeCANDataFrame(df, db_kia, attack=False)\n",
    "    match = re.search(r'day(\\d+)', lname)\n",
    "    day_number = match.group(1)\n",
    "    new_string = f'Day_{day_number}'\n",
    "    df.to_csv(f\"signal_dataset/Benign/Day_{day_number}/\" + lname.rstrip(\".log\") + \".csv\", index=False, index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deserialize signals in real attack data\n",
    "\n",
    "valid_signals = [item for item in colnames if item not in ['time_interval', 'aid_time_interval', 'arbitration_id', 'attack', 'attack_class']]\n",
    "for i in tqdm(range(len(attack_lnames))):\n",
    "    lname = attack_lnames[i]\n",
    "    fp = \"output/CSV_RawWithTimeIntervals_Multiclass/\" + lname.rstrip(\".log\") + \".csv\"\n",
    "    df = pd.read_csv(fp)\n",
    "    df = deserializeCANDataFrame(df, db_kia, attack=True, signals=valid_signals)\n",
    "    df.to_csv(\"signal_dataset/Attack/Real_attacks/\" + lname.rstrip(\".log\") + \".csv\", index=False, index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deserialize signals in simulated attack data\n",
    "\n",
    "valid_signals = [item for item in colnames if item not in ['time_interval', 'aid_time_interval', 'arbitration_id', 'attack', 'attack_class']]\n",
    "for i in tqdm(range(len(simulated_attack_lnames))):\n",
    "    lname = simulated_attack_lnames[i]\n",
    "    fp = \"output/CSV_RawWithTimeIntervals_Multiclass/\" + lname.rstrip(\".log\") + \".csv\"\n",
    "    df = pd.read_csv(fp)\n",
    "    df = deserializeCANDataFrame(df, db_kia, attack=True, signals=valid_signals)\n",
    "    if ('suspension' in lname):\n",
    "        df.to_csv(\"signal_dataset/Attack/Suspension_attacks/\" + lname.rstrip(\".log\") + \".csv\", index=False, index_label=False)\n",
    "    else:\n",
    "        df.to_csv(\"signal_dataset/Attack/Masquerade_attacks/\" + lname.rstrip(\".log\") + \".csv\", index=False, index_label=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_interval</th>\n",
       "      <th>aid_time_interval</th>\n",
       "      <th>arbitration_id</th>\n",
       "      <th>07F.C_DRLLampLhOpenSts</th>\n",
       "      <th>07F.C_DRLLampRhOpenSts</th>\n",
       "      <th>596.CR_Ldc_ActVol_LS_V</th>\n",
       "      <th>5B0.CF_Clu_Odometer</th>\n",
       "      <th>5FF.CF_Vcu_EpbRequest</th>\n",
       "      <th>attack</th>\n",
       "      <th>attack_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.009934</td>\n",
       "      <td>153</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.536743e-07</td>\n",
       "      <td>0.009934</td>\n",
       "      <td>160</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.536743e-07</td>\n",
       "      <td>0.009934</td>\n",
       "      <td>164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.049042e-03</td>\n",
       "      <td>0.010002</td>\n",
       "      <td>220</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.536743e-07</td>\n",
       "      <td>0.010989</td>\n",
       "      <td>340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_interval  aid_time_interval arbitration_id  07F.C_DRLLampLhOpenSts  \\\n",
       "0   0.000000e+00           0.009934            153                     NaN   \n",
       "1   9.536743e-07           0.009934            160                     NaN   \n",
       "2   9.536743e-07           0.009934            164                     NaN   \n",
       "3   1.049042e-03           0.010002            220                     NaN   \n",
       "4   9.536743e-07           0.010989            340                     NaN   \n",
       "\n",
       "   07F.C_DRLLampRhOpenSts  596.CR_Ldc_ActVol_LS_V  5B0.CF_Clu_Odometer  \\\n",
       "0                     NaN                     NaN                  NaN   \n",
       "1                     NaN                     NaN                  NaN   \n",
       "2                     NaN                     NaN                  NaN   \n",
       "3                     NaN                     NaN                  NaN   \n",
       "4                     NaN                     NaN                  NaN   \n",
       "\n",
       "   5FF.CF_Vcu_EpbRequest  attack  attack_class  \n",
       "0                    NaN       0             0  \n",
       "1                    NaN       0             0  \n",
       "2                    NaN       0             0  \n",
       "3                    NaN       0             0  \n",
       "4                    NaN       0             0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   time_interval           1000 non-null   float64\n",
      " 1   aid_time_interval       1000 non-null   float64\n",
      " 2   arbitration_id          1000 non-null   object \n",
      " 3   07F.C_DRLLampLhOpenSts  0 non-null      float64\n",
      " 4   07F.C_DRLLampRhOpenSts  0 non-null      float64\n",
      " 5   596.CR_Ldc_ActVol_LS_V  5 non-null      float64\n",
      " 6   5B0.CF_Clu_Odometer     0 non-null      float64\n",
      " 7   5FF.CF_Vcu_EpbRequest   4 non-null      float64\n",
      " 8   attack                  1000 non-null   int64  \n",
      " 9   attack_class            1000 non-null   int64  \n",
      "dtypes: float64(7), int64(2), object(1)\n",
      "memory usage: 78.2+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lname = attack_lnames[0]\n",
    "# fp = \"CSV_Signals_Multiclass\\\\\" + lname.rstrip(\".log\") + \".csv\"\n",
    "\n",
    "lname = os.listdir(\"signal_dataset/Attack/Real_attacks/\")[0]\n",
    "fp = \"signal_dataset/Attack/Real_attacks/\" + lname\n",
    "df = pd.read_csv(fp, nrows = 1000)\n",
    "sample_df = pd.concat([df.iloc[:, :5], df.iloc[:, -5:]], axis=1)\n",
    "display(sample_df.head())\n",
    "print(sample_df.info())\n",
    "\n",
    "del sample_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `arbitration_id` column is still in hexadecimal and should be converted to decimal before use for feature selection. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant and missing values\n",
    "\n",
    "We perform feature selection only on attack logs which will be used to train the model. \n",
    "\n",
    "In this section, we check for and remove only columns with constant columns and missing values, with further feature selection steps performed on the train set, after train/test split. \n",
    "\n",
    "For columns with missing values, we only remove columns which are completely NaNs through out any log. Other columns are retained, a forward fill is performed, and rows from the beginning containing any NaNs are removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. of columns: 550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Min_speedometer_attack_2.csv',\n",
       " 'EMS_attack.csv',\n",
       " 'Parking_break_attack.csv',\n",
       " 'Fuzzing_valid_IDs_DoS.csv',\n",
       " 'Power_steering_attack.csv',\n",
       " 'Min_speedometer_attack_1.csv',\n",
       " 'EMS_replay_attack.csv',\n",
       " 'Fuzzing_random_IDs.csv',\n",
       " 'Reverse_speedometer_fuzzing_attack.csv',\n",
       " 'Break_warning_attack.csv',\n",
       " 'Gear_shifter_attack_2.csv',\n",
       " 'EMS_replay_long_attack.csv',\n",
       " 'Max_speedometer_attack.csv',\n",
       " 'Wiper_warning_attack.csv',\n",
       " 'Steering_angle_replay.csv',\n",
       " 'Multiple_attacks_1.csv',\n",
       " 'DoS_attack.csv',\n",
       " 'Break_and_fog_light_attack.csv',\n",
       " 'Multiple_attacks_2.csv',\n",
       " 'Drive_mode_changing_attack.csv',\n",
       " 'FCA_warning_attack.csv',\n",
       " 'Gear_shifter_attack_1.csv',\n",
       " 'Steering_angle_attack.csv',\n",
       " 'Min_speedometer_attack_3.csv',\n",
       " 'Door_open_warning_attack.csv',\n",
       " 'Fuzzing_valid_IDs.csv']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns to retain\n",
    "with open('output/colnames', 'rb') as fp:          # Includes time_interval, aid_time_interval, arbitration_id, all signals, and attack\n",
    "    colnames = pickle.load(fp)\n",
    "print(\"Total no. of columns:\", len(colnames))\n",
    "\n",
    "# with open('output/attack_lnames', 'rb')  as fp:    # Attack log names    \n",
    "#     attack_lnames = pickle.load(fp)\n",
    "\n",
    "attack_lnames = os.listdir(\"signal_dataset/Attack/Real_attacks/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant signals\n",
    "\n",
    "There may be signals that remain constant over time. Such signals can be removed from consideration for training a ML model. Simpler rule-based methods can be used to detect anomalies in such signals. \n",
    "\n",
    "Here on we consider only attack logs which are going to be used for the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check constant signals in all logs\n",
    "# constant_signal_dict = {}           # Dictionary containing all constant columns as keys and the respective constant values as values, across all logs\n",
    "# all_lnames = attack_lnames\n",
    "\n",
    "# print(\"Finding constant signals in all attack logs..\")\n",
    "# for i in tqdm(range(len(all_lnames))):\n",
    "#     lname = all_lnames[i]\n",
    "#     fp = \"CSV_Signals_Multiclass\\\\\" + lname.rstrip(\".log\") + \".csv\"\n",
    "#     df = pd.read_csv(fp)\n",
    "\n",
    "#     const_sigs_df   = df.nunique()  # List of signals in current DF that have constant columns\n",
    "#     const_sigs_df   = const_sigs_df[const_sigs_df <= 1]\n",
    "    \n",
    "#     const_sigs_dict_df = {}         # Dictionary of constant columns and values of CURRENT DF\n",
    "#     for idx in const_sigs_df.index:          \n",
    "#         if const_sigs_df[idx] == 0:\n",
    "#             const_sigs_dict_df[idx] = np.nan\n",
    "#         else: \n",
    "#             unique_vals = df[idx].unique()\n",
    "#             const_sigs_dict_df[idx] = unique_vals[~np.isnan(unique_vals)][0]\n",
    "    \n",
    "#     constant_signal_dict = const_sigs_dict_df if not constant_signal_dict else dict(const_sigs_dict_df.items() & constant_signal_dict.items())\n",
    "\n",
    "# print(\"No. of constant signals in attack logs:\", len(constant_signal_dict))\n",
    "# # print(constant_signal_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding constant signals in all attack logs..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [04:56<00:00, 11.41s/it]\n"
     ]
    }
   ],
   "source": [
    "# Check constant signals in all logs, not considering columns which are completely NaN\n",
    "sig = []\n",
    "const_val = []\n",
    "log = []\n",
    "print(\"Finding constant signals in all attack logs..\")\n",
    "for i in tqdm(range(len(attack_lnames))):\n",
    "    lname = attack_lnames[i]\n",
    "    # fp = \"signal_dataset/Attack/Real_attacks/\" + lname.rstrip(\".log\") + \".csv\"\n",
    "    fp = \"signal_dataset/Attack/Real_attacks/\" + lname\n",
    "    df = pd.read_csv(fp)\n",
    "\n",
    "    const_sigs_df   = df.nunique(dropna=True)  # List of signals in current DF that have constant columns\n",
    "    const_sigs_df   = const_sigs_df[const_sigs_df <= 1]\n",
    "    \n",
    "    for idx in const_sigs_df.index:   \n",
    "        sig.append(idx)\n",
    "        log.append(lname)\n",
    "        if const_sigs_df[idx] == 0:\n",
    "            const_val.append(np.nan)\n",
    "        else: \n",
    "            unique_vals = df[idx].unique()\n",
    "            const_val.append(unique_vals[~np.isnan(unique_vals)][0])\n",
    "        \n",
    "const_vals_df = pd.DataFrame({\n",
    "    \"signal\" : sig,\n",
    "    \"constant_value\" : const_val,\n",
    "    \"log_name\" : log\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"No. of columns with a constant value in at least one attack log:\", len(const_vals_df[\"signal\"].unique()))\n",
    "\n",
    "temp_df = const_vals_df.groupby(['signal', 'constant_value']).size().reset_index(name='logs')\n",
    "print(\"No. of columns with the same value in all attack logs:\", len(temp_df[temp_df.logs == len(attack_lnames)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update list of columns to retain, excluding the constant columns\n",
    "# colnames = [x for x in colnames if x not in list(constant_signal_dict.keys())]\n",
    "const_cols = temp_df[temp_df.logs == len(attack_lnames)].signal\n",
    "colnames = [x for x in colnames if x not in list(const_cols)]\n",
    "print(\"No. of columns retained after removing constant columns:\", len(colnames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns with missing values\n",
    "\n",
    "nan_columns = []    # List of columns with NaN throughout\n",
    "nlogs_no_nans = 0   # Number of logs with no columns that are NaN throughout\n",
    "\n",
    "sig = []\n",
    "log = []\n",
    "\n",
    "for i in tqdm(range(len(attack_lnames))):\n",
    "    lname = attack_lnames[i]\n",
    "    # fp = \"CSV_Signals_Multiclass\\\\\" + lname.rstrip(\".log\") + \".csv\"\n",
    "    fp = \"signal_dataset/Attack/Real_attacks/\" + lname\n",
    "    df = pd.read_csv(fp)  \n",
    "                                  \n",
    "    df = df[colnames]       # Keep only valid AIDs\n",
    "    df = df.ffill()         # Forward-fill signal values\n",
    "\n",
    "    nan_counts = df.isnull().sum()                      # Remove rows with NaNs\n",
    "    nan_counts = nan_counts[nan_counts == len(df)]\n",
    "\n",
    "    if len(nan_counts) == 0:\n",
    "        nlogs_no_nans = nlogs_no_nans + 1\n",
    "\n",
    "    # nan_columns = list(set(nan_columns) | set(nan_counts.index))\n",
    "    else: \n",
    "        for idx in nan_counts.index:\n",
    "            sig.append(idx)\n",
    "            log.append(lname)\n",
    "\n",
    "print('No. of logs with no columns that are null throughout:', nlogs_no_nans)\n",
    "# print(\"No. of columns that are null throughout in any log:\", len(nan_columns))\n",
    "# print(nan_columns)\n",
    "\n",
    "na_vals_df = pd.DataFrame({\n",
    "    \"signal\" : sig,\n",
    "    \"log_name\" : log\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"No. of columns missing values in the entire column in at least one attack log:\", len(na_vals_df[\"signal\"].unique()))\n",
    "print(\"No. of columns missing values in the entire column in all logs:\", len(na_vals_df.signal.value_counts() == len(attack_lnames)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update list of columns to retain, excluding the constant columns\n",
    "# colnames = [x for x in colnames if x not in nan_columns]\n",
    "na_cols = na_vals_df[\"signal\"].unique()\n",
    "colnames = [x for x in colnames if x not in na_cols]\n",
    "print(\"No. of columns retained after removing NaN columns:\", len(colnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove binary attack label\n",
    "colnames = [x for x in colnames if x != 'attack']\n",
    "print(\"No. of columns retained:\", len(colnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save updated list of colnames\n",
    "with open('output/colnames_const_nans_removed', 'wb') as fp:\n",
    "    pickle.dump(list(colnames), fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsampling and train/test split\n",
    "\n",
    "We will downsample the benign class to obtain a 1:1 ratio between the benign class and all the attack classes. \n",
    "\n",
    "We first use a sliding window to obtain windows of data, label the windows using the row labels, and then downsample the benign class. \n",
    "\n",
    "We then split the dataset into training and test sets, maintaining the proportion of the classes in either set. \n",
    "\n",
    "Here, we also convert the `arbitration_id` column from hexadecimal to decimal\n",
    "\n",
    "TODO: Convert `arbitration_id` to decimal in all saved datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(helper_functions)\n",
    "from helper_functions import *\n",
    "\n",
    "with open('output/colnames_const_nans_removed', 'rb') as fp:\n",
    "    colnames = pickle.load(fp)\n",
    "\n",
    "# with open('attack_lnames', 'rb')  as fp:    # Attack log names    \n",
    "#     attack_lnames = pickle.load(fp)\n",
    "attack_lnames = os.listdir(\"signal_dataset/Attack/Real_attacks/\")\n",
    "\n",
    "# Load the DBC file\n",
    "with open(\"hyundai_kia_generic.dbc\") as fin:\n",
    "    db_kia = cantools.database.load(fin)\n",
    "print(db_kia.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(helper_functions)\n",
    "from helper_functions import *\n",
    "\n",
    "# Parameters for sliding window\n",
    "k = 150     # Window size\n",
    "\n",
    "benign_windows = []\n",
    "attack_windows = []\n",
    "attack_window_labels = []\n",
    "\n",
    "# The following concurrent lists are to allow faster preparation of the training set for feature selection\n",
    "benign_win_lnames = [] # Names of the log where each benign window originated from \n",
    "attack_win_lnames = [] # Names of the log where each attack window originated from \n",
    "benign_start_indices = []\n",
    "attack_start_indices = []\n",
    "\n",
    "for i in tqdm(range(len(attack_lnames))):\n",
    "    lname = attack_lnames[i]\n",
    "    # fp = \"CSV_Signals_Multiclass\\\\\" + lname.rstrip(\".log\") + \".csv\"\n",
    "    fp = \"signal_dataset/Attack/Real_attacks/\" + lname\n",
    "    df = pd.read_csv(fp)     \n",
    "\n",
    "    df = df[colnames]                                                       # Keep only selected columns\n",
    "\n",
    "    df['arbitration_id'] = df.arbitration_id.apply(lambda x: int(x, 16))    # Convert to decimal\n",
    "\n",
    "    df = df.ffill()                                                         # Forward-fill and delete NaN rows\n",
    "\n",
    "    nan_row_idx = df.isnull().any(axis=1)                                   # Indices of rows with NaNs\n",
    "    print(f'{lname:<40}: {nan_row_idx.sum()} of {len(df)} rows discarded')      \n",
    "    df = df[~nan_row_idx]                                                   # Drop rows with NaNs\n",
    "\n",
    "    windows = []\n",
    "    labels  = [] \n",
    "\n",
    "    for j in range(len(df) - k):    # Create windows \n",
    "        df_sub = df.iloc[j:(j+k), :]\n",
    "        windows.append(df_sub)\n",
    "        labels.append(getWindowLabel(df_sub['attack']))\n",
    "        # labels.append(int(df_sub.attack.any()))\n",
    "\n",
    "    benign_windows_df = [x for x,m in zip(windows, labels) if m == 0]   # All benign windows in current DF\n",
    "    benign_windows           = benign_windows       + benign_windows_df\n",
    "    benign_win_lnames        = benign_win_lnames        + [lname for x in benign_windows_df]\n",
    "    benign_start_indices     = benign_start_indices + [x.index[0] for x in benign_windows_df]\n",
    "\n",
    "    attack_windows_df = [x for x,m in zip(windows, labels) if m != 0]   # All attack windows in current DF\n",
    "    attack_windows       = attack_windows       + attack_windows_df\n",
    "    attack_window_labels = attack_window_labels + [label for label in labels if label != 0]\n",
    "    attack_win_lnames    = attack_win_lnames    + [lname for x in attack_windows_df]\n",
    "    attack_start_indices = attack_start_indices + [x.index[0] for x in attack_windows_df]\n",
    "\n",
    "print(\"No. of benign windows =\", len(benign_windows))\n",
    "print(\"No. of attack windows =\", len(attack_windows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersample the benign class\n",
    "\n",
    "sample_rate = 2\n",
    "benign_windows = benign_windows[::sample_rate]\n",
    "benign_start_indices = benign_start_indices[::sample_rate]\n",
    "benign_win_lnames = benign_win_lnames[::sample_rate]\n",
    "\n",
    "print(\"After downsampling\")\n",
    "print(\"------------------\")\n",
    "print(\"No. of benign windows =\", len(benign_windows))\n",
    "print(\"No. of attack windows =\", len(attack_windows))\n",
    "\n",
    "print()\n",
    "print('len(benign_start_indices) =', len(benign_start_indices))\n",
    "print('len(benign_lnames) =', len(benign_win_lnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train, validation, and test sets - 60, 20, 20\n",
    "\n",
    "seed = 101\n",
    "# benign_train, benign_test, benign_lnames_train, benign_lnames_test, benign_startidx_train, benign_startidx_test = train_test_split(benign_windows, benign_win_lnames, benign_start_indices, test_size=0.2, random_state=seed, shuffle=True)\n",
    "# attack_train, attack_test, attack_label_train, attack_label_test, attack_lnames_train, attack_lnames_test, attack_startidx_train, attack_startidx_test = train_test_split(attack_windows, \n",
    "#                                                                                     attack_window_labels,\n",
    "#                                                                                     attack_win_lnames, \n",
    "#                                                                                     attack_start_indices,\n",
    "#                                                                                     test_size=0.2, \n",
    "#                                                                                     random_state=seed, \n",
    "#                                                                                     shuffle=True, \n",
    "#                                                                                     stratify=attack_window_labels)\n",
    "\n",
    "# benign_train, benign_val, benign_lnames_train, benign_lnames_val, benign_startidx_train, benign_startidx_val = train_test_split(benign_train, benign_lnames_train, benign_startidx_train, test_size=0.25, random_state=seed, shuffle=True)\n",
    "# attack_train, attack_val, attack_label_train, attack_label_val, attack_lnames_train, attack_lnames_val, attack_startidx_train, attack_startidx_val = train_test_split(attack_train, \n",
    "#                                                                                     attack_label_train, \n",
    "#                                                                                     attack_lnames_train,\n",
    "#                                                                                     attack_startidx_train, \n",
    "#                                                                                     test_size=0.25, \n",
    "#                                                                                     random_state=seed, \n",
    "#                                                                                     shuffle=True, \n",
    "#                                                                                     stratify=attack_label_train)\n",
    "\n",
    "benign_lnames_train, benign_lnames_test, benign_startidx_train, benign_startidx_test = train_test_split(benign_win_lnames, benign_start_indices, test_size=0.2, random_state=seed, shuffle=True)\n",
    "attack_label_train, attack_label_test, attack_lnames_train, attack_lnames_test, attack_startidx_train, attack_startidx_test = train_test_split(\n",
    "                                                                                    attack_window_labels,\n",
    "                                                                                    attack_win_lnames, \n",
    "                                                                                    attack_start_indices,\n",
    "                                                                                    test_size=0.2, \n",
    "                                                                                    random_state=seed, \n",
    "                                                                                    shuffle=True, \n",
    "                                                                                    stratify=attack_window_labels)\n",
    "\n",
    "benign_lnames_train, benign_lnames_val, benign_startidx_train, benign_startidx_val = train_test_split(benign_lnames_train, benign_startidx_train, test_size=0.25, random_state=seed, shuffle=True)\n",
    "attack_label_train, attack_label_val, attack_lnames_train, attack_lnames_val, attack_startidx_train, attack_startidx_val = train_test_split( \n",
    "                                                                                    attack_label_train, \n",
    "                                                                                    attack_lnames_train,\n",
    "                                                                                    attack_startidx_train, \n",
    "                                                                                    test_size=0.25, \n",
    "                                                                                    random_state=seed, \n",
    "                                                                                    shuffle=True, \n",
    "                                                                                    stratify=attack_label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training set\")\n",
    "print(\"------------\")\n",
    "print(\"No. of benign windows =\", len(benign_startidx_train))\n",
    "print(\"No. of attack windows =\", len(attack_startidx_train))\n",
    "\n",
    "print(\"Validation set\")\n",
    "print(\"------------\")\n",
    "print(\"No. of benign windows =\", len(benign_startidx_val))\n",
    "print(\"No. of attack windows =\", len(attack_startidx_val))\n",
    "\n",
    "print(\"Testing set\")\n",
    "print(\"------------\")\n",
    "print(\"No. of benign windows =\", len(benign_startidx_test))\n",
    "print(\"No. of attack windows =\", len(attack_startidx_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training, validation, and testing set information to disk\n",
    "\n",
    "# Training\n",
    "startidx_train = benign_startidx_train + attack_startidx_train\n",
    "lnames_train   = benign_lnames_train   + attack_lnames_train\n",
    "labels_train   = [0 for x in benign_startidx_train] + attack_label_train\n",
    "\n",
    "with open('model_data/startidx_train', 'wb') as fp:\n",
    "    pickle.dump(startidx_train, fp)\n",
    "with open('model_data/lnames_train', 'wb') as fp:\n",
    "    pickle.dump(lnames_train, fp)\n",
    "with open('model_data/labels_train', 'wb') as fp:\n",
    "    pickle.dump(labels_train, fp)\n",
    "\n",
    "# Validation\n",
    "startidx_val = benign_startidx_val + attack_startidx_val\n",
    "lnames_val   = benign_lnames_val   + attack_lnames_val\n",
    "labels_val   = [0 for x in benign_startidx_val] + attack_label_val\n",
    "\n",
    "with open('model_data/startidx_val', 'wb') as fp:\n",
    "    pickle.dump(startidx_val, fp)\n",
    "with open('model_data/lnames_val', 'wb') as fp:\n",
    "    pickle.dump(lnames_val, fp)\n",
    "with open('model_data/labels_val', 'wb') as fp:\n",
    "    pickle.dump(labels_val, fp)\n",
    "\n",
    "# Testing\n",
    "startidx_test = benign_startidx_test + attack_startidx_test\n",
    "lnames_test   = benign_lnames_test   + attack_lnames_test\n",
    "labels_test   = [0 for x in benign_startidx_test] + attack_label_test\n",
    "\n",
    "with open('model_data/startidx_test', 'wb') as fp:\n",
    "    pickle.dump(startidx_test, fp)\n",
    "with open('model_data/lnames_test', 'wb') as fp:\n",
    "    pickle.dump(lnames_test, fp)\n",
    "with open('model_data/labels_test', 'wb') as fp:\n",
    "    pickle.dump(labels_test, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del benign_windows, attack_windows\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training set for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in benign rows for feature selection\n",
    "\n",
    "benign_train_flat = []\n",
    "\n",
    "print(\"Processing benign rows..\") \n",
    "\n",
    "lnames = list(set(benign_lnames_train))\n",
    "for i in tqdm(range(len(lnames))):\n",
    "    lname = lnames[i]\n",
    "    indices = [a for a,b in zip(benign_startidx_train, benign_lnames_train) if (b == lname)]    # Get starting indices for all windows in this log\n",
    "    unique_indices = set(indices)                                                               # Set of all indices for rows to include in train set from this log\n",
    "    for i in indices:\n",
    "        unique_indices.update([j for j in range(i+1, i+150)])                                   # Add the indices of ALL rows in each time window\n",
    "    \n",
    "    # fp = \"CSV_Signals_Multiclass\\\\\" + lname.rstrip(\".log\") + \".csv\"                             # Read in the rows from the file\n",
    "    fp = \"signal_dataset/Attack/Real_attacks/\" + lname\n",
    "    # df = pd.read_csv(fp, skiprows= lambda x: x not in unique_indices)\n",
    "    df = pd.read_csv(fp)\n",
    "    \n",
    "    df = df[colnames]                                                       # Keep only selected columns\n",
    "    df['arbitration_id'] = df.arbitration_id.apply(lambda x: int(x, 16))    # Convert to decimal\n",
    "    df = df.ffill()                                                         # Forward-fill and delete NaN rows\n",
    "\n",
    "    benign_train_flat.append(df[df.index.isin(unique_indices)])\n",
    "\n",
    "benign_train_flat = pd.concat(benign_train_flat, ignore_index=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in attack rows for feature selection\n",
    "\n",
    "attack_train_flat = []\n",
    "\n",
    "print(\"Processing attack rows..\") \n",
    "\n",
    "lnames = list(set(attack_lnames_train))\n",
    "for i in tqdm(range(len(lnames))):\n",
    "    lname = lnames[i]\n",
    "    indices = [a for a,b in zip(attack_startidx_train, attack_lnames_train) if (b == lname)]    # Get starting indices for all windows in this log\n",
    "    unique_indices = set(indices)                                                               # Set of all indices for rows to include in train set from this log\n",
    "    for i in indices:\n",
    "        unique_indices.update([j for j in range(i+1, i+150)])                                   # Add the indices of ALL rows in each time window\n",
    "    \n",
    "    # fp = \"CSV_Signals_Multiclass\\\\\" + lname.rstrip(\".log\") + \".csv\"                             # Read in the rows from the file\n",
    "    fp = \"signal_dataset/Attack/Real_attacks/\" + lname\n",
    "    # df = pd.read_csv(fp, skiprows= lambda x: x not in unique_indices)\n",
    "    df = pd.read_csv(fp)\n",
    "    \n",
    "    df = df[colnames]                                                       # Keep only selected columns\n",
    "    df['arbitration_id'] = df.arbitration_id.apply(lambda x: int(x, 16))    # Convert to decimal\n",
    "    df = df.ffill()                                                         # Forward-fill and delete NaN rows\n",
    "\n",
    "    attack_train_flat.append(df[df.index.isin(unique_indices)])\n",
    "\n",
    "attack_train_flat = pd.concat(attack_train_flat, ignore_index=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine benign and attack rows\n",
    "train_flat = pd.concat([benign_train_flat, attack_train_flat])\n",
    "train_flat = train_flat.drop_duplicates(ignore_index=True)\n",
    "del benign_train_flat, attack_train_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of unique rows in training set:\", len(train_flat))\n",
    "display(train_flat.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for constant columns and missing data\n",
    "\n",
    "print(\"No. of columns with constant values:\", len(train_flat.columns[train_flat.nunique() <= 1]))\n",
    "print(\"No. of columns with missing values:\", len(train_flat.columns[train_flat.isna().any()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"No. of rows of each label:\")\n",
    "display(train_flat.attack.value_counts())\n",
    "\n",
    "# Convert attack column to categorical column\n",
    "train_flat_norm = train_flat\n",
    "train_flat_norm['attack'] = pd.Categorical(train_flat_norm['attack'], ordered=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization (MinMaxScaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the DBC file\n",
    "with open(\"hyundai_kia_generic.dbc\") as fin:\n",
    "    db_kia = cantools.database.load(fin)\n",
    "print(db_kia.version)\n",
    "print(\"No. of AIDs defined in DBC =\", len(db_kia.messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(helper_functions)\n",
    "from helper_functions import *  \n",
    "\n",
    "# Get min and max vals for all columns from training set\n",
    "minmax_vals = getColumnMinMax(train_flat, db_kia, colnames)\n",
    "\n",
    "# Save minimum and maximum values \n",
    "with open('output/minmax_vals', 'wb') as fp:\n",
    "    pickle.dump(minmax_vals, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale training set\n",
    "train_flat_norm = minMaxScaleWindow(train_flat, minmax_vals)\n",
    "display(train_flat_norm.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"No. of columns with missing values:\", len(train_flat.columns[train_flat.isna().any()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection\n",
    "\n",
    "We perform the following feature selection methods on the training set to help us identify the features that are the most predictive of the labels:\n",
    "\n",
    "* Information gain (Supervised method)\n",
    "* ANOVA F-score (Supervised method)\n",
    "* Pearson correlation (Unsupervised method)\n",
    "* Feature variance (Unsupervised method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information gain\n",
    "\n",
    "We calculate the information gain of each feature with respect to the label. Higher the gain, the more informative the feature is in predicting the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate information gain\n",
    "info_gain = mutual_info_classif(train_flat_norm.drop(columns=['attack']), train_flat_norm.attack, random_state=seed, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to indexed Series for use later\n",
    "col_info_gain = pd.Series(list(info_gain), index = [col for col in train_flat_norm.columns if col != 'attack'])\n",
    "col_info_gain = col_info_gain.sort_values(ascending=False)\n",
    "\n",
    "# Save info gain values to disk\n",
    "with open('output/col_info_gain', 'wb') as fp:\n",
    "    pickle.dump((col_info_gain), fp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize \n",
    "print(\"Top 5 columns by information gain:\")\n",
    "print(col_info_gain[:5])\n",
    "print(\"Bottom 5 columns by information gain:\")\n",
    "print(col_info_gain[-5:])\n",
    "\n",
    "# Histogram of Information gain \n",
    "fig = plt.hist(col_info_gain)\n",
    "plt.title(\"Distribution of information gain among features in train_flat\")\n",
    "plt.xlabel(\"Information gain\")\n",
    "plt.ylabel(\"No. of features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that most features provide information gain in the bottom 10% percentile of all information gain scores. We choose to discard these. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset features\n",
    "feature_sub_info_gain = list(col_info_gain[col_info_gain >= 0.025].index)\n",
    "print(\"No. of features selected on the basis of Information Gain:\", len(feature_sub_info_gain))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANOVA F-value\n",
    "\n",
    "ANOVA assumes that the data within groups is normally distributed, which is why we first use the Shapiro-Wilk test for normality. We apply it to each feature within each label group. If the Shapiro-Wilk test suggests that all columns are normally distributed, we can consider the ANOVA F-values for feature selection, otherwise we do not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for normality\n",
    "\n",
    "for label in train_flat_norm.attack.unique():\n",
    "    df_sub = train_flat_norm[train_flat_norm.attack == label]\n",
    "    col_shapiro = df_sub.apply(lambda x: shapiro(x), axis=0)\n",
    "\n",
    "    fig = plt.hist((col_shapiro.iloc[0]))\n",
    "    plt.title(\"Distribution of W from Shapiro-Willk test for attack label = \" + str(label))\n",
    "    plt.xlabel(\"W\")\n",
    "    plt.ylabel(\"No. of features\")\n",
    "    plt.show()\n",
    "\n",
    "    fig = plt.hist((col_shapiro.iloc[1]))\n",
    "    plt.title(\"Distribution of p from Shapiro-Willk test for attack label = \" + str(label))\n",
    "    plt.xlabel(\"p\")\n",
    "    plt.ylabel(\"No. of features\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the W and p-values of features in each group, we cannot make the generaization that the data is normally distributed in each group. Therefore, we choose to not use the ANOVA f-value for feature selection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ANOVA F-value\n",
    "anova_fvalues, anova_pvalues = f_classif(train_flat_norm.drop(columns=['attack']), train_flat_norm.attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with F-values and p-values for use later\n",
    "col_anova = pd.DataFrame({'fvalue': anova_fvalues, 'pvalue': anova_pvalues}, index=[col for col in train_flat_norm.columns if col != 'attack'])\n",
    "col_anova = col_anova.sort_values(by='fvalue', ascending=False)\n",
    "\n",
    "# Save ANOVA F-values and p-values to disk\n",
    "with open('output/col_anova', 'wb') as fp:\n",
    "    pickle.dump(col_anova, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize p-values \n",
    "fig = plt.hist((col_anova.pvalue))\n",
    "plt.title(\"Distribution of p-values among features in train_flat\")\n",
    "plt.xlabel(\"-log10(p-value)\")\n",
    "plt.ylabel(\"No. of features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retain features with p-values under 0.05\n",
    "col_anova_sub = col_anova[col_anova.pvalue <= 0.05]\n",
    "print(\"No. of features wit p-values <= 0.05:\", len(col_anova_sub))\n",
    "# display(col_anova_sub.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of F-values in col_anova_sub\n",
    "fig = plt.hist((col_anova_sub.fvalue))\n",
    "plt.title(\"Distribution of F-value among features in train_flat with p <= 0.05\")\n",
    "plt.xlabel(\"F-value\")\n",
    "plt.ylabel(\"No. of features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of F-values in col_anova_sub (in logoarithm scale)\n",
    "fig = plt.hist(np.log10(col_anova_sub.fvalue))\n",
    "plt.title(\"Distribution of F-value among features in train_flat with p <= 0.05\")\n",
    "plt.xlabel(\"log10(F-value)\")\n",
    "plt.ylabel(\"No. of features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairwise Pearson correlation\n",
    "\n",
    "We calculate the pairwise Pearson correlation among the features and retain only features that are not strongly correlated with each other (i.e. show absolute correlation coefficient <= 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate pairwise Pearson correlation among all feature columns\n",
    "pearson_corr = train_flat_norm.drop(columns=['attack']).corr(method='pearson')\n",
    "\n",
    "with open('output/col_pearson_corr_mat', 'wb') as fp:\n",
    "    pickle.dump(pearson_corr, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize correlation matrix\n",
    "f = plt.figure(figsize=(35, 35))\n",
    "plt.matshow(pearson_corr, fignum=f.number)\n",
    "plt.xticks(range(train_flat.select_dtypes(['number']).shape[1]), train_flat.select_dtypes(['number']).columns, rotation=90)\n",
    "plt.yticks(range(train_flat.select_dtypes(['number']).shape[1]), train_flat.select_dtypes(['number']).columns)\n",
    "cb = plt.colorbar()\n",
    "plt.title('Pearson correlation matrix for columns in train_flat (without clustering)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify features that show strong collinearity \n",
    "\n",
    "high_corr = set()\n",
    "for i in range(len(pearson_corr.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(pearson_corr.iloc[i, j]) > 0.99:\n",
    "            high_corr.add(pearson_corr.columns[i])\n",
    "print(\"No. of columns showing high correlation to other columns:\", len(high_corr))\n",
    "# print(high_corr)\n",
    "\n",
    "# Discard features show strong collinearity \n",
    "feature_sub_pearson = [feat for feat in train_flat_norm.columns if (feat not in high_corr) and (feat != 'attack')]\n",
    "print(\"No. of columns retained from pairwise Pearson correlation tests:\", len(feature_sub_pearson))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate feature variance\n",
    "variance_selector = VarianceThreshold()\n",
    "variance_selector.fit(train_flat_norm.drop(columns=['attack']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to indexed Series for use later\n",
    "col_variance = pd.Series(list(variance_selector.variances_), index=list(variance_selector.feature_names_in_))\n",
    "col_variance = col_variance.sort_values(ascending=False)\n",
    "\n",
    "# Save feature variances to disk\n",
    "with open('output/col_variance', 'wb') as fp:\n",
    "    pickle.dump(col_variance, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "print(\"Top 5 columns by feature variance:   \", col_variance[:5])\n",
    "print(\"Bottom 5 columns by feature variance:\", col_variance[-5:])\n",
    "\n",
    "# Histogram of variance\n",
    "fig = plt.hist(col_variance)\n",
    "plt.title(\"Distribution of feature variances among features in train_flat\")\n",
    "plt.xlabel(\"Variance\")\n",
    "plt.ylabel(\"No. of features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose to discard the approximately 200 features that show variance of less than 0.025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retain features with high variance\n",
    "feature_variance = list(col_variance[col_variance >= 0.025].index)\n",
    "print(\"No. of features retained on the basis of feature variance:\", len(feature_variance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final feature set\n",
    "\n",
    "In this section we inspect the feature sets selected from information gain, pairwise pearson correlation tests, and feature variance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature sets\n",
    "print(\"No. of features retained from information gain         :\", len(feature_sub_info_gain))\n",
    "print(\"No. of features retained from pearson correlation tests:\", len(feature_sub_pearson))\n",
    "print(\"No. of features retained from feature variance         :\", len(feature_variance))\n",
    "\n",
    "venn3([set(feature_sub_info_gain), set(feature_sub_pearson), set(feature_variance)], ('InfoGain_features', 'Pearson_features', 'Variance_features'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider the features that are present in all three sets as the final feature set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intersection\n",
    "final_colnames = set(feature_sub_info_gain).intersection(set(feature_sub_pearson).intersection(set(feature_variance)))\n",
    "\n",
    "print(\"No. of features in final feature set:\", len(final_colnames))\n",
    "print(\"Final feature set:\", final_colnames)\n",
    "\n",
    "# Save final feature set to disk\n",
    "with open('final_colnames', 'wb') as fp:\n",
    "    pickle.dump(list(final_colnames), fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save individual feature sets\n",
    "with open('output/feature_sub_info_gain', 'wb' ) as fp:\n",
    "    pickle.dump(list(feature_sub_info_gain), fp)\n",
    "\n",
    "with open('output/feature_variance', 'wb') as fp:\n",
    "    pickle.dump(list(feature_variance), fp)\n",
    "\n",
    "with open('output/feature_sub_pearson', 'wb') as fp:\n",
    "    pickle.dump(list(feature_sub_pearson), fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for model\n",
    "\n",
    "We apply the preprocessing steps to each time window and save it as memory-mapped files for fast I/O during training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(helper_functions)\n",
    "from helper_functions import *\n",
    "\n",
    "def writeMemoryMappedData(startidx, lnames, labels, colnames, minmax_vals, file_name):\n",
    "\n",
    "    data_count = 0\n",
    "    mmapped_array = np.memmap(\"model_data/\" + file_name + \".npy\", dtype=\"float\", mode=\"w+\", shape=(len(startidx), 150, len(colnames)))\n",
    "\n",
    "    pbar_count = len(startidx)               # Progress bar setup\n",
    "    with tqdm(total = pbar_count) as pbar:   # Progress bar\n",
    "        \n",
    "        for lname in list(set(lnames)):\n",
    "\n",
    "            # fp = \"CSV_Signals_Multiclass/\" + lname.rstrip(\".log\") + \".csv\"\n",
    "            fp = \"signal_dataset/Attack/Real_attacks/\" + lname\n",
    "            df = pd.read_csv(fp)                            # Read in log\n",
    "\n",
    "            df = df[[x for x in colnames if x != 'attack']] # Keep only selected columns\n",
    "            if 'arbitration_id' in colnames:                # If AID is an included feature, convert it to integer\n",
    "                df['arbitration_id'] = df.arbitration_id.apply(lambda x: int(x, 16))\n",
    "            df = df.ffill()                                 # Forward-fill and delete NaN rows\n",
    "            df = minMaxScaleWindowModel(df, minmax_vals)    # Minmax scaling\n",
    "\n",
    "            indices = [(a,c) for a,b,c in zip(startidx, lnames, labels) if (b == lname) ]     # Get starting indices of all windows in current log\n",
    "            \n",
    "            for tup in indices:                     # Each tuple is (start index, window label)\n",
    "                win = df.iloc[tup[0]:(tup[0]+150)]  # Window starting at tup[0]\n",
    "                mmapped_array[data_count] = win\n",
    "                data_count = data_count + 1      \n",
    "\n",
    "                pbar.update(1)                      # Progress bar update\n",
    "\n",
    "    mmapped_array.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output/final_colnames', 'rb') as fp:\n",
    "    colnames = pickle.load(fp)\n",
    "# with open('attack_lnames', 'rb')  as fp:    # Attack log names    \n",
    "#     attack_lnames = pickle.load(fp)\n",
    "attack_lnames = os.listdir(\"signal_dataset/Attack/Real_attacks/\")\n",
    "with open('output/minmax_vals', 'rb') as fp:\n",
    "        minmax_vals = pickle.load(fp)\n",
    "\n",
    "print(\"No. of features:\", len(colnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data info\n",
    "with open('model_data/startidx_train', 'rb') as fp:\n",
    "        startidx = pickle.load(fp)\n",
    "with open('model_data/lnames_train', 'rb') as fp:\n",
    "    lnames = pickle.load(fp)\n",
    "with open('model_data/labels_train', 'rb') as fp:\n",
    "    labels = pickle.load(fp)\n",
    "\n",
    "# Write training data to memory-mapped file\n",
    "writeMemoryMappedData(startidx, lnames, labels, colnames, minmax_vals, \"train_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation data info\n",
    "with open('model_data/startidx_val', 'rb') as fp:\n",
    "        startidx = pickle.load(fp)\n",
    "with open('model_data/lnames_val', 'rb') as fp:\n",
    "    lnames = pickle.load(fp)\n",
    "with open('model_data/labels_val', 'rb') as fp:\n",
    "    labels = pickle.load(fp)\n",
    "\n",
    "# Write validation data to memory-mapped file\n",
    "writeMemoryMappedData(startidx, lnames, labels, colnames, minmax_vals, \"val_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing data info\n",
    "with open('model_data/startidx_test', 'rb') as fp:\n",
    "    startidx = pickle.load(fp)\n",
    "with open('model_data/lnames_test', 'rb') as fp:\n",
    "    lnames = pickle.load(fp)\n",
    "with open('model_data/labels_test', 'rb') as fp:\n",
    "    labels = pickle.load(fp)\n",
    "\n",
    "# Write testing data to memory-mapped file\n",
    "writeMemoryMappedData(startidx, lnames, labels, colnames, minmax_vals, \"test_data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wsl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
